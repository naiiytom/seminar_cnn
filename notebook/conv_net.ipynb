{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as trf\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/HAM10000_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_type = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "imageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                for x in glob(os.path.join(\"..\\\\data\", '*', '*.jpg'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = df['image_id'].map(imageid_path.get)\n",
    "df['cell_type'] = df['dx'].map(lesion_type.get)\n",
    "df['target'] = pd.Categorical(df['cell_type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, df.sort_values(['cell_type']).groupby('cell_type')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=128).iterrows()):\n",
    "        img = mpimg.imread(c_row['path'])\n",
    "        c_ax.imshow(img)\n",
    "        c_ax.axis('off')\n",
    "fig.savefig('./output/category_samples.png', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinData(data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['target'][index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation, test = train_test_split(test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "validation = validation.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name, model, data_gen, val_gen, optimizer, criterion, num_epochs=20):\n",
    "    since = time.time()\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    fpath = '../model/'\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if(epoch%5==0):\n",
    "            print(f'Saving model...')\n",
    "            torch.save(model.state_dict(), f'{fpath}_{name}_{epoch}_{time.time()}__.pth')\n",
    "        print(f'Epoch {epoch} / {num_epochs-1}')\n",
    "        print('--' * 4)\n",
    "        trainings_error = []\n",
    "        validation_error = []\n",
    "        trainings_err_tmp = []\n",
    "        model.train()\n",
    "        for data, label in data_gen:\n",
    "            data_gpu = data.to(DEVICE)\n",
    "            label_gpu = label.to(DEVICE)\n",
    "            output = model(data_gpu)\n",
    "            err = criterion(output, label_gpu)\n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "            trainings_err_tmp.append(err.item())\n",
    "        mean_trainings_error = np.mean(trainings_err_tmp)\n",
    "        trainings_error.append(mean_trainings_error)\n",
    "        print('trainings error:', mean_trainings_error)\n",
    "            \n",
    "        with torch.set_grad_enabled(False):\n",
    "            val_err_tmp = []\n",
    "            count_val = 0\n",
    "            model.eval()\n",
    "            for data, label in val_gen:\n",
    "                data_gpu = data.to(DEVICE)\n",
    "                label_gpu = label.to(DEVICE)\n",
    "                output = model(data_gpu)\n",
    "                err = criterion(output, label_gpu)\n",
    "                val_err_tmp.append(err.item())\n",
    "                count_val += 1\n",
    "                if count_val >= 10:\n",
    "                    count_val = 0\n",
    "                    mean_val_error = np.mean(val_err_tmp)\n",
    "                    validation_error.append(mean_val_error)\n",
    "                    print('validation error:', mean_val_error)\n",
    "                    break\n",
    "                    \n",
    "    time_since = time.time() - since\n",
    "    print(f'Train completed in {time_since//60:.0f}m {time_since%60:.0f}s')\n",
    "    print(f'Leat loss: {min(mean_val_error)}')\n",
    "    return trainings_errors, validation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_gen):\n",
    "    results = []\n",
    "    targets = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_gen:\n",
    "            data_gpu = data.to(DEVICE)\n",
    "            label_gpu = label.to(DEVICE)\n",
    "            outputs = model(data_gpu)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            results.append(preds.item())\n",
    "            targets.append(label.item())\n",
    "    return results , targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = trf.Compose([trf.RandomHorizontalFlip(), trf.RandomVerticalFlip(), trf.CenterCrop(256),\n",
    "                      trf.RandomCrop(224), trf.ToTensor(), trf.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = trf.Compose([trf.ToTensor(), trf.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 30,\n",
    "    'shuffle': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **without augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_wo = SkinData(train, transform=normalized)\n",
    "train_gen_wo = data.DataLoader(train_set_wo, **params)\n",
    "\n",
    "val_set_wo = SkinData(validation, transform=normalized)\n",
    "val_gen_wo = data.DataLoader(val_set_wo, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = models.resnet34(pretrained=True)\n",
    "for param in res_net.parameters():\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = res_net.fc.in_features\n",
    "res_net.fc = nn.Linear(num_ftrs, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = res_net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(res_net.parameters(), lr=0.000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_res_wo, val_loss_res_wo = train_model('ResNet', res_net, train_gen_wo, val_gen_wo, optimizer, criterion, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = SkinData(test, transform=(normalized))\n",
    "test_gen = data.DataLoader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_res_wo, target = predict(res_net, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **with augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_w = SkinData(train, transform=composed)\n",
    "train_gen_w = data.DataLoader(train_set_w, **params)\n",
    "\n",
    "val_set_w = SkinData(validation, transform=composed)\n",
    "val_gen_w = data.DataLoader(val_set_w, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = models.resnet34(pretrained=True)\n",
    "for param in res_net.parameters():\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = res_net.fc.in_features\n",
    "res_net.fc = nn.Linear(num_ftrs, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = res_net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(res_net.parameters(), lr=0.000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_res_w, val_loss_res_w = train_model('ResNet_with_augment', res_net, train_gen_w, val_gen_w, optimizer, criterion, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_res_w, target = predict(res_net, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **without augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = models.vgg16(pretrained=True)\n",
    "for param in vgg_16.parameters():\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = vgg_16.classifier[6].in_features\n",
    "features = list(vgg_16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_ftrs, 7)])\n",
    "vgg_16.classifier = nn.Sequential(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = vgg_16.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vgg_16.parameters(), lr=0.000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_vgg_wo, val_loss_vgg_wo = train_model('vgg', vgg_16, train_gen_wo, val_gen_wo, optimizer, criterion, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vgg_wo, target = predict(vgg_16, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **with augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = models.vgg16(pretrained=True)\n",
    "for param in vgg_16.parameters():\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = vgg_16.classifier[6].in_features\n",
    "features = list(vgg_16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_ftrs, 7)])\n",
    "vgg_16.classifier = nn.Sequential(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = vgg_16.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vgg_16.parameters(), lr=0.000001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_vgg_w, val_loss_vgg_w = train_model('vgg_with_aug', vgg_16, train_gen_w, val_gen_w, optimizer, criterion, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vgg_w, target = predict(vgg_16, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
